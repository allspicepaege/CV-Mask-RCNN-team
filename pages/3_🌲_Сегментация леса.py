#imports
import streamlit as st
import time
import torch
import requests
import segmentation_models_pytorch as smp
import numpy as np
import cv2

#from's
from io import BytesIO
from PIL import Image
from ultralytics import YOLO

from models.model_3.model_unet import prediction
from models.model_3.model_unet import get_model

st.set_page_config(
    page_title="–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ª–µ—Å–∞",
    page_icon="üå≤",
)

st.markdown(
    '<h1 style="text-align: center;">–ú–æ–¥–µ–ª—å, —Å–µ–≥–º–µ–Ω—Ç–∏—Ä—É—é—â–∞—è –ª–µ—Å –Ω–∞ –∞—ç—Ä–æ—Å–Ω–∏–º–∫–∞—Ö</h1>',
    unsafe_allow_html=True
)

# –§–æ—Ä–º–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
uploaded_files = st.file_uploader('–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)
image_url = st.text_input('–í—Å—Ç–∞–≤—å—Ç–µ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ')

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
images = []

if uploaded_files:
    images = [Image.open(file) for file in uploaded_files]

elif image_url:
    try:
        response = requests.get(image_url)
        img = Image.open(BytesIO(response.content))
        images.append(img)
    except Exception as e:
        st.error(f'–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ —Å—Å—ã–ª–∫–µ. –û—à–∏–±–∫–∞: {e}')

if not images:
    st.warning('–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!')
    st.stop()

######################
### MODEL
######################

@st.cache_resource()
def load_model():    
    model = get_model()
    model.load_state_dict(torch.load('./models/model_3/best.pt'))
    model.eval()
    return model

model = load_model()

######################
### MASK FUNCTION
######################

def overlay_mask(image, mask, color=(0, 255, 0), alpha=0.5):

    image = np.array(image.convert("RGB"))  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ RGB
    
    # –ú–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –º–∞—Å–∫–∏ –ø–æ–¥ —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    mask_resized = cv2.resize(mask.astype(np.uint8), (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)

    # –°–æ–∑–¥–∞—ë–º —Ü–≤–µ—Ç–Ω—É—é –º–∞—Å–∫—É
    color_mask = np.zeros_like(image)
    color_mask[mask_resized == 1] = color  

    # –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ–º —Å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é
    overlayed = cv2.addWeighted(image, 1, color_mask, alpha, 0)

    return Image.fromarray(overlayed)

######################
### PREDICTION
######################

start_time = time.time()

for img in images:
    st.image(img, caption='–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_container_width=True)

    # –ü–æ–ª—É—á–∞–µ–º –º–∞—Å–∫—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    mask = prediction(model, img)

    # –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ–º –º–∞—Å–∫—É
    masked_image = overlay_mask(img, mask)

    st.image(masked_image, caption='–°–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_container_width=True)

end_time = time.time()
elapsed_time = end_time - start_time

st.write('‚è≥ –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (—Å–µ–∫):')
st.markdown(f"""
<h3 style='text-align: center; font-size: 30px; font-weight: bold; padding: 5px; border-radius:5px;'>
{elapsed_time:.2f}
</h3>
""", unsafe_allow_html=True)